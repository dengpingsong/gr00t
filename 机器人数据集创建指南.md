# 🤖 GR00T 机器人数据集创建完整指南

## 概述

本指南详细介绍如何从零开始创建符合 GR00T LeRobot 格式的机器人数据集，包括记录关节信息、摄像头数据和标注信息的完整流程。

## 📁 1. 数据集目录结构

首先创建标准的目录结构：

```
my_robot_dataset/
├── meta/                           # 元数据文件
│   ├── episodes.jsonl             # 片段信息
│   ├── tasks.jsonl                # 任务信息  
│   ├── modality.json              # 模态配置 (GR00T特有)
│   ├── info.json                  # 数据集信息
│   └── stats.json                 # 统计信息 (可选)
├── data/                          # 结构化数据
│   └── chunk-000/                 # 数据块
│       ├── episode_000000.parquet
│       ├── episode_000001.parquet
│       └── ...
└── videos/                        # 视频数据
    └── chunk-000/
        ├── observation.images.front_camera/
        │   ├── episode_000000.mp4
        │   └── episode_000001.mp4
        └── observation.images.wrist_camera/
            ├── episode_000000.mp4
            └── episode_000001.mp4
```

## 🎥 2. 摄像头数据记录

### 2.1 摄像头配置示例

```python
import cv2
import numpy as np
from datetime import datetime
import threading
import queue

class CameraRecorder:
    def __init__(self, camera_configs):
        """
        camera_configs: {
            'front_camera': {'device_id': 0, 'resolution': (640, 480), 'fps': 30},
            'wrist_camera': {'device_id': 1, 'resolution': (640, 480), 'fps': 30},
        }
        """
        self.cameras = {}
        self.frame_queues = {}
        self.recording = False
        
        for name, config in camera_configs.items():
            cap = cv2.VideoCapture(config['device_id'])
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, config['resolution'][0])
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, config['resolution'][1])
            cap.set(cv2.CAP_PROP_FPS, config['fps'])
            
            self.cameras[name] = {
                'capture': cap,
                'config': config,
                'writer': None
            }
            self.frame_queues[name] = queue.Queue()
    
    def start_recording(self, episode_id, output_dir):
        """开始录制指定episode的视频"""
        self.recording = True
        
        # 为每个摄像头创建VideoWriter
        for name, camera in self.cameras.items():
            config = camera['config']
            output_path = f"{output_dir}/observation.images.{name}/episode_{episode_id:06d}.mp4"
            
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            writer = cv2.VideoWriter(
                output_path, fourcc, config['fps'], config['resolution']
            )
            camera['writer'] = writer
        
        # 启动录制线程
        self.record_threads = []
        for name in self.cameras.keys():
            thread = threading.Thread(target=self._record_camera, args=(name,))
            thread.start()
            self.record_threads.append(thread)
    
    def _record_camera(self, camera_name):
        """录制单个摄像头的线程函数"""
        camera = self.cameras[camera_name]
        cap = camera['capture']
        writer = camera['writer']
        
        while self.recording:
            ret, frame = cap.read()
            if ret:
                writer.write(frame)
                # 同时保存时间戳用于同步
                timestamp = datetime.now().timestamp()
                self.frame_queues[camera_name].put((timestamp, frame))
    
    def stop_recording(self):
        """停止录制"""
        self.recording = False
        
        # 等待线程结束
        for thread in self.record_threads:
            thread.join()
        
        # 释放VideoWriter
        for camera in self.cameras.values():
            if camera['writer']:
                camera['writer'].release()
                camera['writer'] = None
    
    def get_synchronized_frames(self):
        """获取同步的多摄像头帧"""
        frames = {}
        timestamps = {}
        
        for name, frame_queue in self.frame_queues.items():
            if not frame_queue.empty():
                timestamp, frame = frame_queue.get()
                frames[name] = frame
                timestamps[name] = timestamp
        
        return frames, timestamps
```

### 2.2 使用示例

```python
# 配置摄像头
camera_configs = {
    'front_camera': {
        'device_id': 0,           # USB摄像头0
        'resolution': (640, 480),
        'fps': 30
    },
    'wrist_camera': {
        'device_id': 1,           # USB摄像头1  
        'resolution': (640, 480),
        'fps': 30
    }
}

# 创建录制器
recorder = CameraRecorder(camera_configs)

# 开始录制episode 0
recorder.start_recording(episode_id=0, output_dir="videos/chunk-000")

# ... 执行机器人任务 ...

# 停止录制
recorder.stop_recording()
```

## 🦾 3. 机器人关节信息记录

### 3.1 关节状态记录器

```python
import time
import pandas as pd
import numpy as np
from collections import defaultdict

class RobotStateRecorder:
    def __init__(self, robot_interface):
        """
        robot_interface: 你的机器人接口类
        """
        self.robot = robot_interface
        self.episode_data = defaultdict(list)
        self.recording = False
        self.start_time = None
    
    def start_episode(self, episode_id):
        """开始新的episode录制"""
        self.episode_id = episode_id
        self.episode_data = defaultdict(list)
        self.recording = True
        self.start_time = time.time()
        print(f"开始录制 Episode {episode_id}")
    
    def record_step(self, action=None):
        """记录一个时间步的数据"""
        if not self.recording:
            return
        
        current_time = time.time()
        relative_time = current_time - self.start_time
        
        # 1. 记录时间戳
        self.episode_data['timestamp'].append(relative_time)
        
        # 2. 记录关节状态 (观测)
        joint_states = self.robot.get_joint_states()
        
        # 示例：7DOF机械臂 + 2DOF夹爪
        state_vector = np.concatenate([
            joint_states['left_arm_positions'],     # 7个关节位置
            joint_states['left_arm_velocities'],    # 7个关节速度  
            joint_states['left_gripper_position'],  # 1个夹爪位置
            joint_states['base_position'],          # 3个基座位置
            joint_states['base_orientation'],       # 4个基座四元数
        ])
        
        self.episode_data['observation.state'].append(state_vector)
        
        # 3. 记录动作 (如果提供)
        if action is not None:
            self.episode_data['action'].append(action)
        
        # 4. 记录任务标注 (可选)
        task_description_index = 0  # 对应tasks.jsonl中的索引
        self.episode_data['annotation.human.action.task_description'].append(task_description_index)
        
        # 5. 记录有效性标注
        self.episode_data['annotation.human.validity'].append(1)  # 1=有效, 0=无效
        
    def end_episode(self, save_path):
        """结束episode并保存数据"""
        if not self.recording:
            return
        
        self.recording = False
        
        # 转换为DataFrame
        df_data = {}
        for key, values in self.episode_data.items():
            if key in ['observation.state', 'action']:
                # 状态和动作存储为数组列表
                df_data[key] = values
            else:
                df_data[key] = values
        
        df = pd.DataFrame(df_data)
        
        # 保存为parquet格式
        output_path = f"{save_path}/episode_{self.episode_id:06d}.parquet"
        df.to_parquet(output_path, index=False)
        
        print(f"Episode {self.episode_id} 保存到: {output_path}")
        print(f"数据长度: {len(df)} 步")
        
        return len(df)  # 返回episode长度
```

### 3.2 机器人接口示例

```python
class RobotInterface:
    """机器人接口示例 - 根据你的实际机器人修改"""
    
    def __init__(self):
        # 初始化机器人连接
        # self.robot = your_robot_driver()
        pass
    
    def get_joint_states(self):
        """获取当前关节状态"""
        # 这里需要根据你的机器人API修改
        
        # 示例：7DOF机械臂
        joint_states = {
            'left_arm_positions': np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]),
            'left_arm_velocities': np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),
            'left_gripper_position': np.array([0.05]),  # 夹爪开合度
            'base_position': np.array([0.0, 0.0, 0.0]), # x, y, z
            'base_orientation': np.array([0.0, 0.0, 0.0, 1.0]), # quaternion
        }
        
        return joint_states
    
    def execute_action(self, action):
        """执行动作"""
        # 根据action控制机器人
        # self.robot.set_joint_positions(action[:7])  # 关节位置
        # self.robot.set_gripper(action[7])           # 夹爪
        pass
```

## 📝 4. 元数据文件创建

### 4.1 创建 modality.json

```python
def create_modality_config(save_path):
    """创建模态配置文件"""
    
    modality_config = {
        "state": {
            "left_arm_positions": {"start": 0, "end": 7},
            "left_arm_velocities": {"start": 7, "end": 14}, 
            "left_gripper": {"start": 14, "end": 15},
            "base_position": {"start": 15, "end": 18},
            "base_orientation": {"start": 18, "end": 22}
        },
        "action": {
            "left_arm": {"start": 0, "end": 7},
            "left_gripper": {"start": 7, "end": 8},
            "base_motion": {"start": 8, "end": 11}
        },
        "video": {
            "front_camera": {
                "original_key": "observation.images.front_camera"
            },
            "wrist_camera": {
                "original_key": "observation.images.wrist_camera"
            }
        },
        "annotation": {
            "human.action.task_description": {},
            "human.validity": {}
        }
    }
    
    import json
    with open(f"{save_path}/modality.json", "w") as f:
        json.dump(modality_config, f, indent=2)
```

### 4.2 创建其他元数据

```python
def create_metadata_files(save_path, episodes_info, tasks_list):
    """创建元数据文件"""
    
    # 1. episodes.jsonl
    with open(f"{save_path}/episodes.jsonl", "w") as f:
        for ep_info in episodes_info:
            f.write(json.dumps(ep_info) + "\n")
    
    # 2. tasks.jsonl  
    with open(f"{save_path}/tasks.jsonl", "w") as f:
        for i, task in enumerate(tasks_list):
            f.write(json.dumps({"task_index": i, "task": task}) + "\n")
    
    # 3. info.json
    info = {
        "codebase_version": "1.0.0",
        "data_path": "data",
        "dataset_type": "LeRobotDataset", 
        "fps": 30,
        "robot_type": "my_robot",
        "total_episodes": len(episodes_info),
        "total_frames": sum(ep["length"] for ep in episodes_info),
        "video": True
    }
    
    with open(f"{save_path}/info.json", "w") as f:
        json.dump(info, f, indent=2)
```

## 🚀 5. 完整的数据收集流程

### 5.1 主要收集脚本

```python
import os
import json
from pathlib import Path

def collect_robot_dataset(dataset_path, num_episodes=10):
    """完整的数据收集流程"""
    
    # 1. 创建目录结构
    dataset_path = Path(dataset_path)
    (dataset_path / "meta").mkdir(parents=True, exist_ok=True)
    (dataset_path / "data" / "chunk-000").mkdir(parents=True, exist_ok=True)
    (dataset_path / "videos" / "chunk-000" / "observation.images.front_camera").mkdir(parents=True, exist_ok=True)
    (dataset_path / "videos" / "chunk-000" / "observation.images.wrist_camera").mkdir(parents=True, exist_ok=True)
    
    # 2. 初始化记录器
    camera_configs = {
        'front_camera': {'device_id': 0, 'resolution': (640, 480), 'fps': 30},
        'wrist_camera': {'device_id': 1, 'resolution': (640, 480), 'fps': 30}
    }
    
    camera_recorder = CameraRecorder(camera_configs)
    robot_interface = RobotInterface()
    state_recorder = RobotStateRecorder(robot_interface)
    
    # 3. 数据收集
    episodes_info = []
    tasks_list = ["抓取红色方块", "有效数据"]
    
    for episode_id in range(num_episodes):
        print(f"\n=== Episode {episode_id} ===")
        
        # 开始录制
        camera_recorder.start_recording(episode_id, dataset_path / "videos" / "chunk-000")
        state_recorder.start_episode(episode_id)
        
        # 执行任务 (这里需要你的具体任务逻辑)
        episode_length = execute_robot_task(state_recorder, robot_interface)
        
        # 停止录制
        camera_recorder.stop_recording()
        actual_length = state_recorder.end_episode(dataset_path / "data" / "chunk-000")
        
        # 记录episode信息
        episodes_info.append({
            "episode_index": episode_id,
            "tasks": ["抓取红色方块", "有效数据"],
            "length": actual_length
        })
        
        print(f"Episode {episode_id} 完成，长度: {actual_length}")
    
    # 4. 创建元数据
    create_modality_config(dataset_path / "meta")
    create_metadata_files(dataset_path / "meta", episodes_info, tasks_list)
    
    print(f"\n数据集创建完成: {dataset_path}")
    print(f"总episode数: {len(episodes_info)}")
    print(f"总帧数: {sum(ep['length'] for ep in episodes_info)}")

def execute_robot_task(state_recorder, robot_interface):
    """执行具体的机器人任务"""
    
    # 这里实现你的具体任务逻辑
    # 例如：遥控操作、示教学习、轨迹回放等
    
    for step in range(100):  # 假设任务100步
        # 1. 获取当前状态并记录
        state_recorder.record_step()
        
        # 2. 生成或获取动作
        action = get_next_action()  # 你的动作生成逻辑
        
        # 3. 执行动作
        robot_interface.execute_action(action)
        
        # 4. 延时
        time.sleep(1/30)  # 30FPS
    
    return 100  # 返回episode长度

def get_next_action():
    """获取下一个动作 - 根据你的控制方式实现"""
    # 示例：随机动作
    return np.random.randn(8)  # 7个关节 + 1个夹爪

# 使用示例
if __name__ == "__main__":
    collect_robot_dataset("./my_robot_dataset", num_episodes=50)
```

## 🎮 6. 不同数据收集方式

### 6.1 遥控操作收集

```python
import pygame

class TeleopController:
    def __init__(self):
        pygame.init()
        self.joystick = pygame.joystick.Joystick(0)
        self.joystick.init()
    
    def get_teleop_action(self):
        """获取遥控输入"""
        pygame.event.pump()
        
        # 读取摇杆输入
        left_x = self.joystick.get_axis(0)
        left_y = self.joystick.get_axis(1)
        right_x = self.joystick.get_axis(2)
        right_y = self.joystick.get_axis(3)
        
        # 转换为机器人动作
        action = np.array([
            left_x * 0.1,   # 关节1
            left_y * 0.1,   # 关节2
            right_x * 0.1,  # 关节3
            right_y * 0.1,  # 关节4
            # ... 其他关节
        ])
        
        return action
```

### 6.2 示教学习收集

```python
class DemonstrationRecorder:
    def __init__(self, robot_interface):
        self.robot = robot_interface
    
    def record_demonstration(self, state_recorder):
        """记录人类示教"""
        
        print("开始示教，请移动机器人...")
        
        while True:
            # 检测是否停止
            if self.should_stop():
                break
            
            # 记录当前状态作为示教轨迹
            state_recorder.record_step()
            
            time.sleep(1/30)
        
        print("示教结束")
    
    def should_stop(self):
        """检测停止条件"""
        # 例如：检测按键、力传感器等
        return False
```

## 📊 7. 数据质量检查

### 7.1 数据验证脚本

```python
def validate_dataset(dataset_path):
    """验证数据集完整性"""
    
    dataset_path = Path(dataset_path)
    
    # 1. 检查目录结构
    required_dirs = [
        "meta", "data/chunk-000", 
        "videos/chunk-000"
    ]
    
    for dir_path in required_dirs:
        if not (dataset_path / dir_path).exists():
            print(f"❌ 缺少目录: {dir_path}")
            return False
    
    # 2. 检查元数据文件
    required_files = [
        "meta/episodes.jsonl",
        "meta/tasks.jsonl", 
        "meta/modality.json",
        "meta/info.json"
    ]
    
    for file_path in required_files:
        if not (dataset_path / file_path).exists():
            print(f"❌ 缺少文件: {file_path}")
            return False
    
    # 3. 检查数据一致性
    with open(dataset_path / "meta/episodes.jsonl") as f:
        episodes = [json.loads(line) for line in f]
    
    for ep in episodes:
        ep_id = ep["episode_index"]
        
        # 检查parquet文件
        parquet_path = dataset_path / f"data/chunk-000/episode_{ep_id:06d}.parquet"
        if not parquet_path.exists():
            print(f"❌ 缺少数据文件: episode_{ep_id:06d}.parquet")
            return False
        
        # 检查视频文件
        for camera in ["front_camera", "wrist_camera"]:
            video_path = dataset_path / f"videos/chunk-000/observation.images.{camera}/episode_{ep_id:06d}.mp4"
            if not video_path.exists():
                print(f"❌ 缺少视频文件: {camera} episode_{ep_id:06d}.mp4")
                return False
    
    print("✅ 数据集验证通过!")
    return True

# 使用示例
validate_dataset("./my_robot_dataset")
```

## 🎯 8. 最佳实践建议

### 8.1 数据收集建议

1. **时间同步**: 确保视频和关节数据的时间戳对齐
2. **标定摄像头**: 记录摄像头内参和外参用于后续处理
3. **多样化场景**: 收集不同光照、背景、物体的数据
4. **质量控制**: 实时监控数据质量，及时重录无效数据

### 8.2 存储优化

```python
# 使用合适的数据类型节省空间
state_vector = np.array(joint_positions, dtype=np.float32)  # 而非float64

# 视频压缩设置
fourcc = cv2.VideoWriter_fourcc(*'h264')  # 更好的压缩率
```

### 8.3 标注建议

```python
# 丰富的标注信息
annotations = {
    "task_description": "抓取红色方块并放入蓝色容器",
    "task_phase": "approaching",  # approaching, grasping, lifting, placing
    "success": True,
    "difficulty": "easy",  # easy, medium, hard
    "environment": "lab_table_1"
}
```

通过这个完整的指南，你可以创建高质量的机器人数据集用于GR00T模型训练。记住根据你的具体机器人平台调整接口和配置！
