# GR00T 双摄像头数据处理详解

## 概述

GR00T 微调脚本 (`gr00t_finetune.py`) 通过数据配置系统来处理不同的视频输入模式，包括单摄像头和双摄像头设置。以下是详细的处理流程和机制。

## 1. 数据配置系统

### 1.1 配置类层次结构

```python
# 基础配置 - 单摄像头
class So100DataConfig(BaseDataConfig):
    video_keys = ["video.webcam"]
    state_keys = ["state.single_arm", "state.gripper"]
    action_keys = ["action.single_arm", "action.gripper"]
    language_keys = ["annotation.human.task_description"]

# 双摄像头配置 - 继承自基础配置
class So100DualCamDataConfig(So100DataConfig):
    video_keys = ["video.front", "video.wrist"]  # 定义两个摄像头
    # 其他配置保持不变
```

### 1.2 视频键的定义

- **单摄像头**: `["video.webcam"]`
- **双摄像头**: `["video.front", "video.wrist"]`

每个视频键对应数据集中的一个视频流。

## 2. 数据变换流水线

### 2.1 视频变换序列

```python
def transform(self):
    transforms = [
        # 1. 视频预处理变换
        VideoToTensor(apply_to=self.video_keys),           # 转换为张量
        VideoCrop(apply_to=self.video_keys, scale=0.95),   # 裁剪
        VideoResize(apply_to=self.video_keys, height=224, width=224), # 重大小
        VideoColorJitter(apply_to=self.video_keys, ...),   # 颜色增强
        VideoToNumpy(apply_to=self.video_keys),            # 转换为numpy
        
        # 2. 状态和动作变换
        StateActionToTensor(apply_to=self.state_keys),
        StateActionTransform(apply_to=self.state_keys, ...),
        StateActionToTensor(apply_to=self.action_keys),
        StateActionTransform(apply_to=self.action_keys, ...),
        
        # 3. 连接变换 - 关键步骤！
        ConcatTransform(
            video_concat_order=self.video_keys,    # 指定视频连接顺序
            state_concat_order=self.state_keys,
            action_concat_order=self.action_keys,
        ),
        
        # 4. GR00T模型特定变换
        GR00TTransform(...),
    ]
```

### 2.2 关键：ConcatTransform 如何处理双摄像头

ConcatTransform 是处理双摄像头的核心组件：

```python
class ConcatTransform:
    def apply(self, data: dict) -> dict:
        # 处理视频数据
        if "video" in grouped_keys:
            unsqueezed_videos = []
            
            # 按照 video_concat_order 的顺序处理每个视频流
            for video_key in self.video_concat_order:  # ["video.front", "video.wrist"]
                video_data = data.pop(video_key)  # 获取单个摄像头数据
                
                # 在视频维度前添加一个维度
                # 形状变化: [T, H, W, C] -> [T, 1, H, W, C]
                unsqueezed_video = np.expand_dims(video_data, axis=-4)
                unsqueezed_videos.append(unsqueezed_video)
            
            # 在视频维度上连接所有摄像头
            # 形状: [T, V, H, W, C], 其中 V 是摄像头数量
            unsqueezed_video = np.concatenate(unsqueezed_videos, axis=-4)
            
            # 输出统一的 "video" 键
            data["video"] = unsqueezed_video
```

## 3. 双摄像头数据流

### 3.1 输入数据格式

**单摄像头数据**:
```python
{
    "video.webcam": np.array([T, H, W, C]),      # 单个视频流
    "state.single_arm": np.array([T, D_state]),
    "action.single_arm": np.array([T, D_action]),
}
```

**双摄像头数据**:
```python
{
    "video.front": np.array([T, H, W, C]),       # 前置摄像头
    "video.wrist": np.array([T, H, W, C]),       # 手腕摄像头
    "state.single_arm": np.array([T, D_state]),
    "action.single_arm": np.array([T, D_action]),
}
```

### 3.2 变换后的输出格式

```python
{
    "video": np.array([T, V, H, W, C]),          # V=2 for dual camera
    "state": torch.tensor([T, D_state_total]),   # 连接后的状态
    "action": torch.tensor([T, D_action_total]), # 连接后的动作
    "language": [...],
}
```

其中：
- `T`: 时间步数
- `V`: 视频视角数量 (双摄像头时 V=2)
- `H, W, C`: 图像高度、宽度、通道数
- `D_*`: 各种特征维度

## 4. 模型架构对多视角的支持

### 4.1 视觉编码器处理

GR00T 模型的视觉编码器能够处理多视角输入：

```python
# 在模型内部，视觉编码器会：
# 1. 处理每个视角: [T, V, H, W, C] -> [T, V, D_visual]
# 2. 融合多视角特征: [T, V, D_visual] -> [T, D_fused]
```

### 4.2 注意力机制

模型使用注意力机制来：
- 学习不同视角之间的重要性权重
- 融合来自多个摄像头的互补信息
- 适应不同任务对不同视角的需求

## 5. 实际使用示例

### 5.1 训练双摄像头模型

```bash
# 使用双摄像头配置训练
python scripts/gr00t_finetune.py \
    --dataset-path ./data/dual_cam_dataset \
    --data-config so100_dualcam \
    --embodiment-tag new_embodiment \
    --output-dir ./checkpoints/dual_cam_model
```

### 5.2 数据集要求

双摄像头数据集必须包含：

1. **modality.json** 中定义两个视频流：
```json
{
    "video": {
        "front": {
            "resolution": [640, 480],
            "channels": 3,
            "fps": 30.0
        },
        "wrist": {
            "resolution": [640, 480],
            "channels": 3,
            "fps": 30.0
        }
    }
}
```

2. **视频文件结构**:
```
videos/
├── chunk-000/
│   ├── observation.images.front/
│   │   ├── episode_000000.mp4
│   │   └── episode_000001.mp4
│   └── observation.images.wrist/
│       ├── episode_000000.mp4
│       └── episode_000001.mp4
```

## 6. 调试和故障排除

### 6.1 常见错误

1. **视频键不匹配**:
```
ValueError: Video key front not found in dataset metadata. 
Available keys: dict_keys(['webcam'])
```
**解决方案**: 检查数据配置是否与数据集匹配

2. **分辨率不匹配**:
```
ValueError: Video video.front has invalid resolution (256, 256), expected (640, 480)
```
**解决方案**: 检查输入数据的分辨率是否与元数据一致

### 6.2 验证数据配置

```python
# 检查数据配置
from gr00t.experiment.data_config import DATA_CONFIG_MAP

config = DATA_CONFIG_MAP["so100_dualcam"]
print("Video keys:", config.video_keys)        # ['video.front', 'video.wrist']
print("State keys:", config.state_keys)        # ['state.single_arm', 'state.gripper']
print("Action keys:", config.action_keys)      # ['action.single_arm', 'action.gripper']
```

## 7. 扩展到更多摄像头

要支持更多摄像头（如三摄像头），可以：

1. **创建新的数据配置**:
```python
class So100TripleCamDataConfig(So100DataConfig):
    video_keys = ["video.front", "video.wrist", "video.overhead"]
```

2. **更新数据集的 modality.json**

3. **确保视频文件结构匹配**

这种设计使得 GR00T 能够灵活地处理不同数量和类型的摄像头输入，为各种机器人任务提供丰富的视觉信息。
