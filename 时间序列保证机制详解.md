# GR00T 时间序列一致性保证机制详解

## 概述

在机器人学习中，时间序列的一致性是至关重要的，特别是对于多模态数据（视频、状态、动作）的同步。GR00T 通过多层机制来确保时间序列的准确性和一致性。

## 1. 数据存储层面的时间同步

### 1.1 基于时间戳的数据组织

```python
# Parquet 文件中的数据结构
{
    "timestamp": [0.0, 0.033, 0.066, 0.100, ...],           # 每个数据点的时间戳
    "observation.state": [[...], [...], [...], [...]],      # 状态数据
    "action": [[...], [...], [...], [...]],                 # 动作数据
    "annotation.human.task_description": [0, 0, 0, 1, ...], # 任务标注索引
}
```

每个 episode 的 parquet 文件都包含精确的时间戳，确保所有模态数据在时间上对齐。

### 1.2 视频-数据时间戳映射

```python
def get_video(self, trajectory_id: int, key: str, base_index: int) -> np.ndarray:
    # 1. 获取需要的时间步索引
    step_indices = self.delta_indices[key] + base_index
    
    # 2. 从 parquet 数据中获取对应的时间戳
    timestamp: np.ndarray = self.curr_traj_data["timestamp"].to_numpy()
    video_timestamp = timestamp[step_indices]  # 获取视频对应的时间戳
    
    # 3. 根据时间戳精确获取视频帧
    return get_frames_by_timestamps(
        video_path, video_timestamp, 
        video_backend=self.video_backend
    )
```

关键点：**视频帧不是通过帧索引获取，而是通过时间戳匹配获取**，这确保了即使视频帧率与数据采集频率不完全一致，也能保持时间同步。

## 2. Delta Indices 机制

### 2.1 时间窗口定义

```python
# 在数据配置中定义时间窗口
class So100DataConfig:
    observation_indices = [0]        # 当前时刻的观测
    action_indices = list(range(16)) # 未来16步的动作序列

def modality_config(self):
    return {
        "video": ModalityConfig(
            delta_indices=self.observation_indices,  # [0] - 只取当前帧
            modality_keys=self.video_keys,
        ),
        "state": ModalityConfig(
            delta_indices=self.observation_indices,  # [0] - 只取当前状态
            modality_keys=self.state_keys,
        ),
        "action": ModalityConfig(
            delta_indices=self.action_indices,       # [0,1,2,...,15] - 未来16步动作
            modality_keys=self.action_keys,
        ),
    }
```

### 2.2 时间索引计算

```python
def get_data_by_modality(self, trajectory_id: int, modality: str, key: str, base_index: int):
    # 核心时间索引计算
    step_indices = self.delta_indices[key] + base_index
    
    # 示例：
    # base_index = 10 (当前时刻)
    # observation_indices = [0] → step_indices = [10] (当前观测)
    # action_indices = [0,1,2,3] → step_indices = [10,11,12,13] (未来4步动作)
```

这种机制确保：
- **观测数据**：总是来自当前时刻
- **动作数据**：来自当前时刻开始的未来序列
- **时间关系**：严格保持因果关系

## 3. 视频时间戳精确匹配

### 3.1 时间戳匹配算法

```python
def get_frames_by_timestamps(video_path: str, timestamps: np.ndarray) -> np.ndarray:
    """根据时间戳精确获取视频帧"""
    
    if video_backend == "decord":
        vr = decord.VideoReader(video_path)
        
        # 1. 获取视频中每帧的时间戳
        frame_ts: np.ndarray = vr.get_frame_timestamp(range(len(vr)))
        
        # 2. 为每个请求的时间戳找到最接近的帧
        # 使用广播计算所有时间戳差值
        indices = np.abs(frame_ts[:, :1] - timestamps).argmin(axis=0)
        
        # 3. 批量获取对应帧
        frames = vr.get_batch(indices)
        return frames.asnumpy()
```

### 3.2 多摄像头时间同步

对于双摄像头数据：

```python
# 每个摄像头都使用相同的时间戳序列
video_timestamp = timestamp[step_indices]  # 来自同一个 parquet 文件

# 分别获取各摄像头的帧
front_frames = get_frames_by_timestamps(front_video_path, video_timestamp)
wrist_frames = get_frames_by_timestamps(wrist_video_path, video_timestamp)

# 结果：两个摄像头的帧在时间上完全对齐
```

## 4. 边界处理和填充策略

### 4.1 时间边界处理

```python
def retrieve_data_and_pad(self, array: np.ndarray, step_indices: np.ndarray, 
                         max_length: int, padding_strategy: str = "first_last"):
    """处理超出轨迹边界的时间索引"""
    
    # 识别需要填充的位置
    front_padding_indices = step_indices < 0              # 超出开始边界
    end_padding_indices = step_indices >= max_length      # 超出结束边界
    
    # 获取有效数据
    valid_indices = ~(front_padding_indices | end_padding_indices)
    raw_data = array[step_indices[valid_indices]]
    
    # 应用填充策略
    if padding_strategy == "first_last":
        # 用首末帧填充（适用于绝对位置数据）
        output[front_padding_indices] = array[0]      # 用第一帧填充
        output[end_padding_indices] = array[-1]       # 用最后一帧填充
    elif padding_strategy == "zero":
        # 零填充（适用于相对动作数据）
        output[padding_positions] = 0
```

### 4.2 视频边界处理

```python
def get_video(self, trajectory_id: int, key: str, base_index: int):
    step_indices = self.delta_indices[key] + base_index
    
    # 确保视频索引在有效范围内
    step_indices = np.maximum(step_indices, 0)                    # 不小于0
    step_indices = np.minimum(step_indices, trajectory_length-1)  # 不超过轨迹长度
    
    # 获取对应时间戳
    video_timestamp = timestamp[step_indices]
```

## 5. 时间一致性验证机制

### 5.1 数据加载时验证

```python
def _check_integrity(self):
    """检查数据集的完整性和时间一致性"""
    
    # 1. 验证 parquet 文件中是否包含时间戳
    assert "timestamp" in parquet_data.columns
    
    # 2. 验证时间戳单调递增
    timestamps = parquet_data["timestamp"].to_numpy()
    assert np.all(np.diff(timestamps) >= 0), "时间戳必须单调递增"
    
    # 3. 验证视频文件存在且长度匹配
    for video_key in self.video_keys:
        video_path = self.get_video_path(trajectory_id, video_key)
        assert video_path.exists(), f"视频文件不存在: {video_path}"
```

### 5.2 运行时一致性检查

```python
def get_step_data(self, trajectory_id: int, base_index: int) -> dict:
    """获取单步数据时进行一致性检查"""
    
    # 确保所有模态使用相同的轨迹数据
    self.curr_traj_data = self.get_trajectory_data(trajectory_id)
    
    # 为每个模态获取数据，确保时间基准一致
    for modality in self.modality_keys:
        for key in self.modality_keys[modality]:
            data[key] = self.get_data_by_modality(trajectory_id, modality, key, base_index)
```

## 6. 实际应用示例

### 6.1 时间序列数据流

```python
# 轨迹数据：长度为100步，时间戳从0到3.3秒
trajectory_data = {
    "timestamp": [0.00, 0.033, 0.066, ..., 3.267, 3.300],  # 100步
    "observation.state": [...],  # 100个状态
    "action": [...],            # 100个动作
}

# 获取第50步的数据（base_index=50）
step_data = dataset.get_step_data(trajectory_id=0, base_index=50)

# 结果包含：
# - video: 第50步对应时间戳(1.65s)的视频帧
# - state: 第50步的状态数据  
# - action: 第50-65步的动作序列（16步预测horizon）
# - language: 第50步的语言标注
```

### 6.2 多模态时间对齐验证

```python
# 验证多模态数据的时间对齐
def verify_temporal_alignment(dataset, trajectory_id, base_index):
    step_data = dataset.get_step_data(trajectory_id, base_index)
    
    # 获取视频对应的时间戳
    video_timestamp = dataset.curr_traj_data["timestamp"].iloc[base_index]
    
    # 验证状态数据的时间戳
    state_timestamp = dataset.curr_traj_data["timestamp"].iloc[base_index]
    
    # 确保时间戳一致
    assert video_timestamp == state_timestamp, "视频和状态时间戳不一致"
    
    print(f"时间戳: {video_timestamp:.3f}s - 所有模态数据时间对齐✓")
```

## 7. 时间序列处理的优势

### 7.1 精确的时间同步
- **基于时间戳**而非帧索引的匹配
- **亚毫秒级**的时间精度
- **自动处理**帧率差异

### 7.2 灵活的时间窗口
- **可配置**的观测和动作时间范围
- **因果关系保证**：观测在前，动作在后
- **适应不同**的预测horizon需求

### 7.3 鲁棒的边界处理
- **智能填充**策略处理边界情况
- **数据类型感知**的填充方法
- **保持序列连续性**

这种多层次的时间序列保证机制使得 GR00T 能够处理复杂的多模态机器人数据，确保训练和推理过程中的时间一致性，这对于学习准确的感知-动作映射关系至关重要。
